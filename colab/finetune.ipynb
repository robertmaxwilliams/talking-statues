{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetune.ipynb",
      "provenance": [],
      "mount_file_id": "1P2xPycZjxtiF0gZTVK7xPJv4iPUzEDVx",
      "authorship_tag": "ABX9TyP2uJQyKh2r36fGvLXdDUJR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robertmaxwilliams/talking-statues/blob/master/colab/finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T4zuEGIga51",
        "colab_type": "text"
      },
      "source": [
        "> Make sure google drive is connected and data is accessible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izZlVqlags5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "450d307c-1128-485e-c76f-b579836f04dc"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Mar  6 15:44:51 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.59       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYst5iu6YYGs",
        "colab_type": "code",
        "outputId": "a6a9a88f-3be2-4b66-8c18-83c1388e0e70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "!pip install gpt_2_simple "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gpt_2_simple\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/e4/a90add0c3328eed38a46c3ed137f2363b5d6a07bf13ee5d5d4d1e480b8c3/gpt_2_simple-0.7.1.tar.gz\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (1.17.5)\n",
            "Collecting toposort\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (2019.11.28)\n",
            "Building wheels for collected packages: gpt-2-simple\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.7.1-cp36-none-any.whl size=23581 sha256=407d91f9f805b64eb7cb4a695fe18141a5e45a2ea7e822a05c0c554a6ac22e97\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/f8/23/b53ce437504597edff76bf9c3b8de08ad716f74f6c6baaa91a\n",
            "Successfully built gpt-2-simple\n",
            "Installing collected packages: toposort, gpt-2-simple\n",
            "Successfully installed gpt-2-simple-0.7.1 toposort-1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj60Jj3nYUHz",
        "colab_type": "code",
        "outputId": "3389f1e9-6437-4165-f69e-06d2e845d269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "import gpt_2_simple as gpt2\n",
        "import os\n",
        "\n",
        "class bcolors:\n",
        "    HEADER = \"\\033[95m\"\n",
        "    OKBLUE = \"\\033[94m\"\n",
        "    OKGREEN = \"\\033[92m\"\n",
        "    WARNING = \"\\033[93m\"\n",
        "    FAIL = \"\\033[91m\"\n",
        "    ENDC = \"\\033[0m\"\n",
        "    BOLD = \"\\033[1m\"\n",
        "    UNDERLINE = \"\\033[4m\"\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0bws2-zY3k0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "83d25174-ed99-4a83-9427-9bfe1cb45c88"
      },
      "source": [
        "model_name = \"124M\"\n",
        "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
        "    print(f\"Downloading {model_name} model...\")\n",
        "    gpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 337Mit/s]                                                      \n",
            "Fetching encoder.json:   0%|                                           | 0.00/1.04M [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading 124M model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Fetching encoder.json: 1.05Mit [00:00, 65.7Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 364Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:02, 203Mit/s]                                   \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 216Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 126Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 124Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3duV5vpY35k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir checkpoint && cp -r models/124M checkpoint/run1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXcjSj4hYUID",
        "colab_type": "code",
        "outputId": "cce5210b-6e88-425e-d278-9e890d08ac9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_path = \"/content/drive/My Drive/GRIMM\";\n",
        "sess = gpt2.start_tf_sess()\n",
        "# gpt2.load_gpt2(sess)\n",
        "gpt2.finetune(sess,\n",
        "              # dataset=data_path,\n",
        "              dataset=data_path + \"/CAT-SKIN.txt\",\n",
        "              model_name='124M',\n",
        "              steps=100,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=1,\n",
        "              sample_every=200,\n",
        "              save_every=50,\n",
        "              )\n",
        "\n",
        "def generate_text(prefix):\n",
        "    prefix = prefix[:-100]\n",
        "    output = gpt2.generate(\n",
        "        sess,\n",
        "        prefix=prefix,\n",
        "        include_prefix=False,\n",
        "        return_as_list=True,\n",
        "        length=100,\n",
        "        batch_size=5,\n",
        "        nsamples=5,\n",
        "    )\n",
        "    # print(f'\\n\\n{bcolors.OKGREEN}{prefix} {bcolors.ENDC}{output}\\n')\n",
        "    output = [x.lstrip(prefix) for x in output]\n",
        "    return output\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 1/1 [00:00<00:00,  3.16it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 2702 tokens\n",
            "Training...\n",
            "[1 | 10.28] loss=2.74 avg=2.74\n",
            "[2 | 11.57] loss=2.80 avg=2.77\n",
            "[3 | 12.83] loss=2.66 avg=2.73\n",
            "[4 | 14.09] loss=2.58 avg=2.69\n",
            "[5 | 15.35] loss=2.25 avg=2.60\n",
            "[6 | 16.62] loss=1.92 avg=2.49\n",
            "[7 | 17.89] loss=1.85 avg=2.39\n",
            "[8 | 19.15] loss=1.82 avg=2.32\n",
            "[9 | 20.44] loss=1.57 avg=2.23\n",
            "[10 | 21.73] loss=1.48 avg=2.15\n",
            "[11 | 23.01] loss=1.28 avg=2.07\n",
            "[12 | 24.27] loss=1.13 avg=1.99\n",
            "[13 | 25.54] loss=0.98 avg=1.91\n",
            "[14 | 26.80] loss=0.85 avg=1.82\n",
            "[15 | 28.06] loss=0.74 avg=1.75\n",
            "[16 | 29.34] loss=0.61 avg=1.67\n",
            "[17 | 30.59] loss=0.90 avg=1.62\n",
            "[18 | 31.89] loss=0.41 avg=1.55\n",
            "[19 | 33.16] loss=0.36 avg=1.48\n",
            "[20 | 34.42] loss=0.49 avg=1.43\n",
            "[21 | 35.69] loss=0.32 avg=1.37\n",
            "[22 | 36.95] loss=0.25 avg=1.31\n",
            "[23 | 38.24] loss=0.23 avg=1.26\n",
            "[24 | 39.51] loss=0.12 avg=1.21\n",
            "[25 | 40.78] loss=0.16 avg=1.16\n",
            "[26 | 42.07] loss=0.22 avg=1.12\n",
            "[27 | 43.35] loss=0.08 avg=1.07\n",
            "[28 | 44.62] loss=0.19 avg=1.04\n",
            "[29 | 45.90] loss=0.09 avg=1.00\n",
            "[30 | 47.17] loss=0.05 avg=0.96\n",
            "[31 | 48.45] loss=0.07 avg=0.93\n",
            "[32 | 49.72] loss=0.08 avg=0.90\n",
            "[33 | 50.99] loss=0.06 avg=0.87\n",
            "[34 | 52.27] loss=0.03 avg=0.84\n",
            "[35 | 53.55] loss=0.04 avg=0.81\n",
            "[36 | 54.81] loss=0.09 avg=0.79\n",
            "[37 | 56.08] loss=0.06 avg=0.77\n",
            "[38 | 57.34] loss=0.04 avg=0.74\n",
            "[39 | 58.62] loss=0.04 avg=0.72\n",
            "[40 | 59.88] loss=0.03 avg=0.70\n",
            "[41 | 61.14] loss=0.05 avg=0.68\n",
            "[42 | 62.40] loss=0.02 avg=0.66\n",
            "[43 | 63.66] loss=0.02 avg=0.64\n",
            "[44 | 64.95] loss=0.03 avg=0.63\n",
            "[45 | 66.22] loss=0.03 avg=0.61\n",
            "[46 | 67.48] loss=0.03 avg=0.60\n",
            "[47 | 68.74] loss=0.03 avg=0.58\n",
            "[48 | 70.00] loss=0.02 avg=0.57\n",
            "[49 | 71.27] loss=0.02 avg=0.55\n",
            "[50 | 72.54] loss=0.02 avg=0.54\n",
            "Saving checkpoint/run1/model-50\n",
            "[51 | 77.76] loss=0.03 avg=0.53\n",
            "[52 | 79.04] loss=0.03 avg=0.51\n",
            "[53 | 80.30] loss=0.02 avg=0.50\n",
            "[54 | 81.57] loss=0.05 avg=0.49\n",
            "[55 | 82.84] loss=0.02 avg=0.48\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}