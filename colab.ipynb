{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "colab_test.ipy",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZTrkPPtYUHu",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYst5iu6YYGs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "2cb2b59c-2ba7-48c1-b509-f2316c91ae2d"
      },
      "source": [
        "!pip install gpt_2_simple bottle markovify flask-ngrok flask==0.12.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gpt_2_simple in /usr/local/lib/python3.6/dist-packages (0.7.1)\n",
            "Requirement already satisfied: bottle in /usr/local/lib/python3.6/dist-packages (0.12.18)\n",
            "Requirement already satisfied: markovify in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.6/dist-packages (0.0.25)\n",
            "Requirement already satisfied: flask==0.12.2 in /usr/local/lib/python3.6/dist-packages (0.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (1.17.5)\n",
            "Requirement already satisfied: toposort in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (1.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gpt_2_simple) (4.28.1)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from markovify) (1.1.1)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.6/dist-packages (from flask==0.12.2) (1.0.0)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.6/dist-packages (from flask==0.12.2) (1.1.0)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.6/dist-packages (from flask==0.12.2) (7.0)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from flask==0.12.2) (2.11.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gpt_2_simple) (2.8)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.4->flask==0.12.2) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj60Jj3nYUHz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "3cc2229b-e76f-4ee9-a257-db7df92ccbab"
      },
      "source": [
        "import gpt_2_simple as gpt2\n",
        "import os\n",
        "import requests\n",
        "from random import randint as dice\n",
        "import time\n",
        "import markovify\n",
        "\n",
        "class bcolors:\n",
        "    HEADER = \"\\033[95m\"\n",
        "    OKBLUE = \"\\033[94m\"\n",
        "    OKGREEN = \"\\033[92m\"\n",
        "    WARNING = \"\\033[93m\"\n",
        "    FAIL = \"\\033[91m\"\n",
        "    ENDC = \"\\033[0m\"\n",
        "    BOLD = \"\\033[1m\"\n",
        "    UNDERLINE = \"\\033[4m\"\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1OODX3oYUIB",
        "colab_type": "text"
      },
      "source": [
        "## Downloading model, starting session, and defining generation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0bws2-zY3k0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = \"124M\"\n",
        "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
        "    print(f\"Downloading {model_name} model...\")\n",
        "    gpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3duV5vpY35k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir checkpoint && cp -r models/124M checkpoint/run1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXcjSj4hYUID",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d1988568-bf3e-466a-fdae-a7fff9351076"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess)\n",
        "\n",
        "def generate_text(prefix):\n",
        "    prefix = prefix[:-100]\n",
        "    output = gpt2.generate(\n",
        "        sess,\n",
        "        prefix=prefix,\n",
        "        include_prefix=False,\n",
        "        return_as_list=True,\n",
        "        length=100,\n",
        "        batch_size=5,\n",
        "        nsamples=5,\n",
        "    )\n",
        "    # print(f'\\n\\n{bcolors.OKGREEN}{prefix} {bcolors.ENDC}{output}\\n')\n",
        "    output = [x.lstrip(prefix) for x in output]\n",
        "    return output\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/run1/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGkVvb-FYUIL",
        "colab_type": "text"
      },
      "source": [
        "## Creating and Starting server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8979b9d5-de8f-492c-a9a0-be6e6cb62cd3",
        "id": "1SfRZ5ShiT2C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, render_template, send_from_directory, request\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app) \n",
        "\n",
        "# build text model\n",
        "with open(\"corpus.txt\", encoding=\"utf8\") as f:\n",
        "    corpus = f.read()\n",
        "\n",
        "text_model = markovify.Text(corpus)\n",
        "\n",
        "\n",
        "def generate_from_text_model(text):\n",
        "    # gems = gpt2_test.generate_text(text)\n",
        "    gems = generate_text(text)\n",
        "    ret = \"\"\n",
        "    try:\n",
        "        for i in range(5):\n",
        "            ret += f\"<div class='predictionBox'> <p><pre>{gems[i]}</pre></p> </div>\"\n",
        "    except Exception as e:\n",
        "        print(f\"FEEE\\n{e}\\nEEEEF\")\n",
        "        return \"sorry, model failure: \" + str(e)\n",
        "    return ret\n",
        "\n",
        "\n",
        "def random_color():\n",
        "    return \"{:06x}\".format(dice(0, 0xFFFFFF))\n",
        "\n",
        "\n",
        "def colorize(text):\n",
        "    words = text_model.word_split(text)\n",
        "    ret = \"\"\n",
        "    for w in words:\n",
        "        ret += f\"<span style='background-color:#{random_color()}'>{w}</span>\"\n",
        "    return ret\n",
        "\n",
        "\n",
        "@app.route(\"/static/<filename>\")\n",
        "def server_static(filename):\n",
        "    return send_from_directory(\"./static/\", filename)\n",
        "\n",
        "\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return send_from_directory(\"./\", \"foo.html\")\n",
        "\n",
        "\n",
        "@app.route(\"/generate\", methods=[\"POST\"])\n",
        "def generate():\n",
        "    text = request.form[\"text\"]\n",
        "    return generate_from_text_model(test)\n",
        "\n",
        "\n",
        "@app.route(\"/highlight\", methods=[\"POST\"])\n",
        "def highlight():\n",
        "    time.sleep(0.5)\n",
        "    text = request.form[\"text\"]\n",
        "    return \"<p>\" + colorize(text) + \"</p>\"\n",
        "\n",
        "\n",
        "app.run()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://0a648ab4.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Mar/2020 16:36:14] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [05/Mar/2020 16:36:14] \"\u001b[37mGET /static/index.css HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [05/Mar/2020 16:36:14] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "b''\n",
            "the bread\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Mar/2020 16:37:06] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "b''\n",
            "I an flying above the mountains \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Mar/2020 16:38:01] \"\u001b[37mPOST /generate HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}